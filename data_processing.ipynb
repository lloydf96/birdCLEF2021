{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing:\n",
    "here we select two overlaping 5 second audio segments from the start and end of the audio segment, assuming that the bird audio is likely to be present during the beginning and end of the audio file\n",
    "then we split the dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acafly', 132),\n",
       " ('acowoo', 190),\n",
       " ('aldfly', 227),\n",
       " ('ameavo', 44),\n",
       " ('amecro', 229),\n",
       " ('amegfi', 181),\n",
       " ('amekes', 82)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' list of bird samples in path'''\n",
    "path = os.path.join(os.getcwd(),'train_short_audio')\n",
    "bird_samples = [name for name in os.listdir(path)]\n",
    "bird_sample_numbers = [(name,len([name_1 for name_1 in os.listdir(os.path.join(path, name)) if os.path.isfile(os.path.join( os.path.join(path,name), name_1)) ])) for name in bird_samples ]\n",
    "bird_sample_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitAudio():\n",
    "    ''' split the audio file to four 5 second snippets (2 clips in the\n",
    "    beginning and 2 in the end with overlap)'''\n",
    "    \n",
    "    def __init__(self,sig_path,time_sample_size,sr = 32000,overlap_min = 0.05,overlap_max = 0.5):\n",
    "        self.sig_path = sig_path\n",
    "        self.time_sample_size = time_sample_size\n",
    "        self.overlap_min = overlap_min\n",
    "        self.overlap_max = overlap_max\n",
    "        self.sr = sr\n",
    "    \n",
    "    def __call__ (self,save_path,bird,name):\n",
    "        x,sr = librosa.load(os.path.join(self.sig_path,bird,name),sr = self.sr)\n",
    "        total_duration = len(x)\n",
    "        #seg = int(np.floor(total_duration/(img_time_diff*self.sr)))\n",
    "        overlap = random.uniform(self.overlap_min,self.overlap_max)\n",
    "        \n",
    "        save_path_2 = os.path.join(save_path,name[:-4])\n",
    "        seg_list = [0]\n",
    "        \n",
    "        if total_duration > (2 - overlap) * self.time_sample_size * self.sr:\n",
    "            seg_list = seg_list + [int(np.ceil((1-overlap)*self.time_sample_size*self.sr))]\n",
    "            \n",
    "        if total_duration > 2*self.time_sample_size*self.sr:\n",
    "            seg_list = seg_list + [int(np.floor(total_duration - ((1 - overlap)*self.time_sample_size + self.time_sample_size)*self.sr)),int(np.floor(total_duration - ( self.time_sample_size)*self.sr))]\n",
    "        \n",
    "        if not os.path.exists(save_path_2):\n",
    "            os.makedirs(save_path_2)\n",
    "            \n",
    "        j = 0   \n",
    "        for i in seg_list:  \n",
    "            \n",
    "            # Get start and stop sample\n",
    "            s_start = i #int(max(0,(second - time_sample_size) * 32000))\n",
    "            s_end = i + self.time_sample_size*self.sr#int( min(second * 32000,total_duration))\n",
    "            \n",
    "            out = os.path.join(save_path_2,\"mel_\"+str(j)+\"_\"+name[:-4]+\".ogg\")\n",
    "            j+=1\n",
    "            \n",
    "            soundfile.write(out,x[s_start:s_end],samplerate = self.sr)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Audio chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_audio_path = os.getcwd() + '\\\\train_samples'\n",
    "sig_path = os.getcwd() + '\\\\train_short_audio'\n",
    "\n",
    "if not os.path.exists(sig_path):\n",
    "    os.makedirs(sig_path)\n",
    "        \n",
    "time_sample_size = 5\n",
    "split_audio = SplitAudio(sig_path,time_sample_size)\n",
    "\n",
    "for bird in bird_samples:\n",
    "    \n",
    "    save_path = os.path.join(segmented_audio_path,bird)\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        \n",
    "    file_list = [name for name in os.listdir(os.path.join(sig_path, bird)) ]\n",
    "    \n",
    "    for name in file_list:\n",
    "        split_audio(save_path,bird,name)\n",
    "            # Compute the spectrogram and apply the mel scale\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clip nocall files from train soundscapes. These files would be added later for audio augmentation as a source of noise'''\n",
    "\n",
    "sc_list = pd.read_csv('train_soundscape_labels.csv')\n",
    "sc_list = sc_list[sc_list.birds == 'nocall']\n",
    "sc_list[\"fileprefix\"] = sc_list[\"audio_id\"].apply(str)+\"_\"+sc_list[\"site\"].apply(str)\n",
    "\n",
    "path = os.getcwd() + '\\\\train_soundscapes'\n",
    "\n",
    "def getprefix(x):\n",
    "    x = x.split(\"_\")\n",
    "    return x[0]+\"_\"+x[1]\n",
    "\n",
    "sc_audio_names = pd.DataFrame(data =  [name for name in os.listdir(path)],columns = [\"filename\"])\n",
    "sc_audio_names[\"fileprefix\"] = sc_audio_names.apply(lambda x: getprefix(x[0]) ,axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename      10534_SSW_20170429.ogg\n",
      "fileprefix                 10534_SSW\n",
      "Name: 0, dtype: object\n",
      "filename      11254_COR_20190904.ogg\n",
      "fileprefix                 11254_COR\n",
      "Name: 1, dtype: object\n",
      "filename      14473_SSW_20170701.ogg\n",
      "fileprefix                 14473_SSW\n",
      "Name: 2, dtype: object\n",
      "filename      18003_COR_20190904.ogg\n",
      "fileprefix                 18003_COR\n",
      "Name: 3, dtype: object\n",
      "filename      20152_SSW_20170805.ogg\n",
      "fileprefix                 20152_SSW\n",
      "Name: 4, dtype: object\n",
      "filename      21767_COR_20190904.ogg\n",
      "fileprefix                 21767_COR\n",
      "Name: 5, dtype: object\n",
      "filename      26709_SSW_20170701.ogg\n",
      "fileprefix                 26709_SSW\n",
      "Name: 6, dtype: object\n",
      "filename      26746_COR_20191004.ogg\n",
      "fileprefix                 26746_COR\n",
      "Name: 7, dtype: object\n",
      "filename      2782_SSW_20170701.ogg\n",
      "fileprefix                 2782_SSW\n",
      "Name: 8, dtype: object\n",
      "filename      28933_SSW_20170408.ogg\n",
      "fileprefix                 28933_SSW\n",
      "Name: 9, dtype: object\n",
      "filename      31928_COR_20191004.ogg\n",
      "fileprefix                 31928_COR\n",
      "Name: 10, dtype: object\n",
      "filename      42907_SSW_20170708.ogg\n",
      "fileprefix                 42907_SSW\n",
      "Name: 11, dtype: object\n",
      "filename      44957_COR_20190923.ogg\n",
      "fileprefix                 44957_COR\n",
      "Name: 12, dtype: object\n",
      "filename      50878_COR_20191004.ogg\n",
      "fileprefix                 50878_COR\n",
      "Name: 13, dtype: object\n",
      "filename      51010_SSW_20170513.ogg\n",
      "fileprefix                 51010_SSW\n",
      "Name: 14, dtype: object\n",
      "filename      54955_SSW_20170617.ogg\n",
      "fileprefix                 54955_SSW\n",
      "Name: 15, dtype: object\n",
      "filename      57610_COR_20190904.ogg\n",
      "fileprefix                 57610_COR\n",
      "Name: 16, dtype: object\n",
      "filename      7019_COR_20190904.ogg\n",
      "fileprefix                 7019_COR\n",
      "Name: 17, dtype: object\n",
      "filename      7843_SSW_20170325.ogg\n",
      "fileprefix                 7843_SSW\n",
      "Name: 18, dtype: object\n",
      "filename      7954_COR_20190923.ogg\n",
      "fileprefix                 7954_COR\n",
      "Name: 19, dtype: object\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "outpath = os.path.join(os.getcwd(),\"train_samples\")\n",
    "\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "\n",
    "for _,row in sc_audio_names.iterrows():\n",
    "    y,_ = librosa.load(os.path.join(path,row[0]),sr = 32000)\n",
    "    \n",
    "    out_path_1 = os.path.join(outpath,'nocall',row[1])\n",
    "    if not os.path.exists(out_path_1):\n",
    "        os.makedirs(out_path_1)\n",
    "        \n",
    "    for _,subrow in sc_list[sc_list.fileprefix == row[1]].iterrows():\n",
    "        \n",
    "        s_start = (subrow[3] - 5)*32000 #int(max(0,(second - time_sample_size) * 32000))\n",
    "        s_end = subrow[3]*32000\n",
    "        out = os.path.join(out_path_1,subrow[0]+\".ogg\")\n",
    "        soundfile.write(out,y[s_start:s_end],samplerate = 32000)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arange files and split into test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_audio_path = os.getcwd() + '\\\\train_samples'\n",
    "sig_path = os.getcwd() + '\\\\train_short_audio'\n",
    "#create list of images with label\n",
    "birds = [name for name in os.listdir(segmented_audio_path)]\n",
    "bird_numbers = [[(name,name_1) for name_1 in os.listdir(os.path.join(segmented_audio_path, name))  ] \n",
    "                       for name in birds ]\n",
    "\n",
    "bird_numbers = [name for sublist in bird_numbers for name in sublist]\n",
    "bird_numbers = [[(bird,name,name_1) for name_1 in os.listdir(os.path.join(segmented_audio_path,bird, name)) ]\n",
    "                      for bird,name in bird_numbers]\n",
    "bird_numbers = [name for sublist in bird_numbers for name in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_1 = pd.DataFrame(data = bird_numbers,columns = ['primary_label','folder','filename'])\n",
    "train_metadata_1['key'] = train_metadata_1['primary_label']+train_metadata_1['folder']+'.ogg'\n",
    "\n",
    "train_metadata_2 = pd.read_csv('train_metadata.csv') \n",
    "train_metadata_2['key'] = train_metadata_2['primary_label'].astype(str)+train_metadata_2['filename'].astype(str)\n",
    "\n",
    "train_metadata = train_metadata_1.set_index(['key']).join(train_metadata_2.set_index(['key']),on = 'key',lsuffix = '',rsuffix='_y',how = 'left').reset_index()[['primary_label','folder','secondary_labels','filename']]\n",
    "train_metadata.replace(np.nan,'[]',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train_dev and test set\n",
    "train_metadata['secondary_labels'] = train_metadata['secondary_labels'].apply(lambda x: x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\" \",\"\").split(\",\"))\n",
    "valid_labels = train_metadata.primary_label.unique()\n",
    "train_metadata['secondary_labels'] = train_metadata['secondary_labels'].apply(lambda x: list(set(x) & set(valid_labels)))\n",
    "\n",
    "metadata_to_split = train_metadata.loc[:,['folder','primary_label']].drop_duplicates()\n",
    "x_train_dev,x_test,y_train_dev,y_test = train_test_split(metadata_to_split['folder'],metadata_to_split['primary_label'],test_size = 0.05,stratify = metadata_to_split['primary_label'])\n",
    "\n",
    "train_dev = train_metadata[train_metadata['folder'].isin(x_train_dev.to_list())]\n",
    "test =  train_metadata[train_metadata['folder'].isin(x_test.to_list())]\n",
    "\n",
    "#save train and test csv's\n",
    "train_dev.reset_index(inplace = True)\n",
    "test.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train_dev to train and dev sets\n",
    "metadata_to_split = train_dev.loc[:,['folder','primary_label']].drop_duplicates()\n",
    "x_train,x_dev,y_train,y_dev = train_test_split(metadata_to_split['folder'],metadata_to_split['primary_label'],test_size = 0.1,stratify = metadata_to_split['primary_label'])\n",
    "\n",
    "train = train_dev[train_dev['folder'].isin(x_train.to_list())]\n",
    "dev =  train_dev[train_dev['folder'].isin(x_dev.to_list())]\n",
    "\n",
    "#save train and test csv's\n",
    "train.reset_index(inplace = True)\n",
    "dev.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amekes'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd() + '\\\\train_test_dev_set'\n",
    "copy_dir =  os.getcwd() + '\\\\train_samples'\n",
    "\n",
    "os.makedirs(os.path.join(base_dir,'train'))\n",
    "os.makedirs(os.path.join(base_dir,'test'))\n",
    "os.makedirs(os.path.join(base_dir,'dev'))\n",
    "\n",
    "train.to_csv(os.path.join(base_dir,'train','train.csv'))\n",
    "test.to_csv(os.path.join(base_dir,'test','test.csv'))\n",
    "dev.to_csv(os.path.join(base_dir,'dev','dev.csv'))\n",
    "\n",
    "import shutil\n",
    "\n",
    "for bird in birds:\n",
    "    train_bird_to = os.path.join(base_dir,'train',bird)\n",
    "    test_bird_to = os.path.join(base_dir,'test',bird)\n",
    "    dev_bird_to = os.path.join(base_dir,'dev',bird)\n",
    "    \n",
    "    os.makedirs(train_bird_to)\n",
    "    os.makedirs(test_bird_to)\n",
    "    os.makedirs(dev_bird_to)\n",
    "    \n",
    "    copy_files_from = os.path.join(copy_dir,bird)\n",
    "    train_copy = train[train['primary_label']==bird].loc[:,['folder','filename']]\n",
    "    test_copy = test[test['primary_label']==bird].loc[:,['folder','filename']]\n",
    "    dev_copy = dev[dev['primary_label']==bird].loc[:,['folder','filename']]\n",
    "    \n",
    "    for i,train_row in train_copy.iterrows():\n",
    "        shutil.copy(os.path.join(copy_files_from,train_row[0],train_row[1]),train_bird_to)\n",
    "    \n",
    "    for i,test_row in test_copy.iterrows():\n",
    "        shutil.copy(os.path.join(copy_files_from,test_row[0],test_row[1]),test_bird_to)\n",
    "        \n",
    "    for i,dev_row in dev_copy.iterrows():\n",
    "        shutil.copy(os.path.join(copy_files_from,dev_row[0],dev_row[1]),dev_bird_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "https://www.kaggle.com/hidehisaarai1213/pytorch-training-birdclef2021-starter\n",
    "https://www.kaggle.com/hidehisaarai1213/birdclef2021-infer-between-chunk\n",
    "https://www.kaggle.com/hidehisaarai1213/introduction-to-sound-event-detection\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
